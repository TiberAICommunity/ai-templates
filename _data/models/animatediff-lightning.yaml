name: animatediff
title: AnimateDiff Lightning
model_id: ByteDance/AnimateDiff-Lightning
description: "A lightning-fast text-to-video generation model that generates videos more than ten times faster than the original AnimateDiff. Optimized for Intel GPUs using Ray Serve, it excels at stylized animations with configurable inference steps (1, 2, 4, or 8 steps)."

license_notice: "Model is released under CreativeML OpenRAIL-M license. This deployment supports single and multi-GPU setups - see <a href='https://github.com/rahulunair/xpu_video' target='_blank'>our repository</a> for advanced deployment options."

context_window: "16 frames at 8 FPS"
hardware_required: "Intel Max Series GPU - VM or Bare Metal configurations on Intel Tiber AI Cloud (32GB+ RAM recommended)"

strengths:
  - "10x faster than original AnimateDiff"
  - "Multiple step options (1,2,4,8)"
  - "Strong stylized outputs"
  - "Motion LoRA support"
  - "Video-to-video capability"

use_cases:
  - "Rapid animation prototyping"
  - "Character animations"
  - "Stylized video generation"
  - "Video-to-video transformation"

model_specs:
  frames: 16
  fps: 8
  guidance: 1.0  # Default, works best with this model
  steps: 4      # Recommended setting, can be 1,2,4,8
  performance: "~1 video every 30-45 seconds on single GPU"

recommended_models:
  realistic:
    - "epiCRealism"
    - "Realistic Vision"
    - "DreamShaper"
    - "AbsoluteReality"
    - "MajicMix Realistic"
  anime:
    - "ToonYou"
    - "IMP"
    - "Mistoon Anime"
    - "DynaVision"
    - "RCNZ Cartoon 3d"
    - "MajicMix Reverie"

architecture_diagram: |
  flowchart LR
      Client([Client])
      Traefik[Traefik Proxy]
      Auth[Auth Service]
      Ray[Ray Service]

      Client --> Traefik
      Traefik --> Auth
      Auth --> Traefik
      Traefik --> Ray
      Ray --> Traefik
      Traefik --> Client

      subgraph Internal["Internal Network"]
          Traefik
          Auth
          Ray
      end

deployment_steps:
  - title: "1. Setup Prerequisites"
    description: "Create Intel Tiber AI Cloud account, select GPU Max VM, and connect to your instance."
    link: "https://cloud.intel.com"
    link_text: "Visit Intel Cloud Portal"

  - title: "2. Deploy Service"
    description: "Clone repository and deploy AnimateDiff Lightning model with authentication"
    code: |
      git clone https://github.com/rahulunair/xpu_video.git && \
      cd xpu_video && \
      ./deploy.sh animatediff

  - title: "3. Try Demo UI"
    description: "Launch the demo UI and API documentation interface"
    code: |
      bash ~/xpu_video/deploy_ui.sh

  - title: "4. Setup Authentication"
    description: "Configure authentication token"
    collapsed: true
    code: |
      source .auth_token.env
      echo $VALID_TOKEN  # Verify token is set

  - title: "5. Generate Videos"
    description: "Make requests to generate videos"
    collapsed: true
    code: |
      curl -X POST http://localhost:8000/imagine/generate \
        -H "Authorization: Bearer $VALID_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{
          "prompt": "A girl smiling, epicrealism style",
          "negative_prompt": "blurry, low quality, distorted, static",
          "num_frames": 16,
          "fps": 8,
          "num_inference_steps": 4,
          "guidance_scale": 1.0
        }'

  - title: "6. Management"
    description: "Monitor, stop, or switch models"
    collapsed: true
    code: |
      # Monitor service
      ./monitor_video.sh

      # Stop services
      ./cleanup.sh

      # Switch models
      ./deploy.sh cogvideox-2b --skip-base

tags:
  - label: "Video"
    color: "#3B82F6"
  - label: "Lightning Fast"
    color: "#10B981"
  - label: "8 FPS"
    color: "#8B5CF6"
  - label: "Ray"
    color: "#F59E0B"
  - label: "Animation"
    color: "#EF4444" 