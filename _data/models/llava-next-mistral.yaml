name: llava-next-mistral
title: LLaVa Next Mistral
model_id: llava-hf/llava-v1.6-mistral-7b-hf
description: "Advanced multimodal model with enhanced visual understanding, OCR capabilities, and efficient processing based on Mistral-7B"

license_notice: "Before using this model, please review the license terms and usage rights on the Hugging Face model page."

# TGI specific configuration
tgi: true
architecture_diagram: |
  flowchart LR
      Client([Client])
      Traefik[Traefik Proxy]
      Auth[Auth Service]
      TGI[TGI Service]

      Client --> Traefik
      Traefik --> Auth
      Auth --> Traefik
      Traefik --> TGI
      TGI --> Traefik
      Traefik --> Client

      subgraph Internal["Internal Network"]
          Traefik
          Auth
          TGI
      end

key_features:
  - "üîí Token-based authentication with automatic ban after failed attempts"
  - "üö¶ Rate limiting (global: 10 req/s, per-IP: 10 req/s)"
  - "üõ°Ô∏è Security headers and IP protection"
  - "üîÑ Health monitoring and automatic recovery"
  - "üöÄ Optimized for Intel GPUs"

# Model specific information
context_window: "4096 tokens"
strengths:
  - "Efficient multimodal processing"
  - "Strong OCR capabilities"
  - "Improved visual reasoning"
  - "Lower memory requirements"

use_cases:
  - "Image analysis"
  - "OCR tasks"
  - "Visual question answering"
  - "Document understanding"

configuration: |
  MODEL_NAME=llava-next-mistral-tgi
  MODEL_ID=llava-hf/llava-v1.6-mistral-7b-hf
  TGI_VERSION=2.4.0-intel-xpu
  PORT=8087
  SHM_SIZE=2g
  MAX_CONCURRENT_REQUESTS=1
  MAX_BATCH_SIZE=1
  MAX_TOTAL_TOKENS=4096
  MAX_INPUT_LENGTH=2048
  MAX_WAITING_TOKENS=10

deployment_steps:
  - title: "Setup Prerequisites"
    description: "Create Intel Tiber AI Cloud account and select GPU Max VM"
    link: "https://cloud.intel.com"
    link_text: "Visit Intel Cloud Portal"

  - title: "Initial Setup"
    description: "Clone repository and generate your authentication token"
    code: |
      git clone https://github.com/tiberaicommunity/xpu_tgi && cd xpu_tgi
      python utils/generate_token.py
      # Save the generated token for next step

  - title: "Start Model"
    description: "Launch model service using your generated token"
    code: |
      VALID_TOKEN=YOUR_TOKEN ./start.sh llava-v1.6-mistral-7b-hf

tags:
  - label: "Multimodal"
    color: "#3B82F6"
  - label: "4K context"
    color: "#10B981"
  - label: "Vision"
    color: "#8B5CF6"
  - label: "TGI"
    color: "#EF4444"
  - label: "Mistral"
    color: "#EC4899"

example_usage:
  - title: "Basic Image Analysis"
    description: "Simple example of analyzing an image"
    code: |
      from huggingface_hub import InferenceClient
      import base64

      def encode_image(image_path):
          with open(image_path, "rb") as image_file:
              return base64.b64encode(image_file.read()).decode('utf-8')

      client = InferenceClient("http://localhost:8000")
      image_data = encode_image("path/to/image.jpg")
      prompt = f"<image>{image_data}</image>\nDescribe what you see in this image in detail."

      response = client.text_generation(
          prompt,
          max_new_tokens=200,
          temperature=0.2
      )

  - title: "OCR Example"
    description: "Extract text from images"
    code: |
      # Example for text extraction from images
      prompt = f"<image>{image_data}</image>\nExtract and list all text visible in this image."

      response = client.text_generation(
          prompt,
          max_new_tokens=150,
          temperature=0.1
      )

  - title: "Visual Question Answering"
    description: "Complex visual analysis with multiple questions"
    code: |
      prompt = f"""<image>{image_data}</image>
      Answer the following questions about the image:
      1. What are the main objects present?
      2. What colors are dominant?
      3. Is there any text visible?
      4. Describe the spatial layout."""

      response = client.text_generation(
          prompt,
          max_new_tokens=300,
          temperature=0.2
      )

best_practices:
  - category: "Image Processing"
    items:
      - "Ensure images are clear and well-lit"
      - "Keep images under 1024x1024 pixels"
      - "Use high-quality images for OCR tasks"
      - "Consider image compression for large files"

  - category: "Prompting Strategies"
    items:
      - "Be specific about what aspects of the image to analyze"
      - "For OCR tasks: Request specific formatting of extracted text"
      - "For OCR tasks: Specify if order/layout matters"
      - "For visual analysis: Break down complex queries into specific questions"
      - "Include spatial relationship questions when relevant"

  - category: "Temperature Settings"
    items:
      - "0.1: OCR and text extraction"
      - "0.2: Detailed image analysis and object detection"
      - "0.3-0.4: General image description"
      - "0.5-0.7: Creative image interpretation"

image_requirements:
  - "Maximum image dimensions: 1024x1024 pixels"
  - "Images larger than 1024x1024 will be automatically resized"
  - "Supported formats: JPEG, PNG, WebP"
  - "Images are processed using CLIP's image processor"

resource_requirements:
  - "Minimum GPU Memory: 8GB"
  - "Recommended GPU Memory: 12GB"
  - "CPU RAM: 16GB recommended"
